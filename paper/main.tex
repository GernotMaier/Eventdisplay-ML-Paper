\documentclass[12pt]{article}
\usepackage{aas_macros}
\usepackage{natbib}
\usepackage[utf8]{inputenc}
\usepackage[left=3cm,right=3cm,top=3cm,bottom=3cm]{geometry}
\usepackage{color}
\usepackage[colorlinks = true,
            linkcolor = blue,
            urlcolor  = blue,
            citecolor = blue]{hyperref}
 \usepackage{graphicx}
 \usepackage{subfigure}
 \usepackage{pythonhighlight}
 \usepackage{comment}
 \usepackage{tablefootnote}
\usepackage{longtable}
\usepackage{tabularx}
\usepackage{booktabs} % toprule, etc.
\usepackage{makecell}
\usepackage{soul}
\usepackage{dirtree}
\sethlcolor{lightgray}
\usepackage{listings}
\lstset{basicstyle=\ttfamily,
  showstringspaces=false,
  commentstyle=\color{red},
  keywordstyle=\color{blue},
  backgroundcolor=\color{lightgray},
  numbers=left
}
\lstdefinestyle{yaml}{
     basicstyle=\color{blue}\footnotesize,
     rulecolor=\color{black},
     string=[s]{'}{'},
     stringstyle=\color{blue},
     comment=[l]{:},
     commentstyle=\color{black},
     morecomment=[l]{-}
}
\usepackage[most]{tcolorbox}

%textmarker style from colorbox doc
\tcbset{textmarker/.style={%
        enhanced,
        parbox=false,boxrule=0mm,boxsep=0mm,arc=0mm,
        outer arc=0mm,left=6mm,right=3mm,top=7pt,bottom=7pt,
        toptitle=1mm,bottomtitle=1mm,oversize}}


% define new colorboxes
\newtcolorbox{hintBox}{textmarker,
    borderline west={6pt}{0pt}{yellow},
    colback=yellow!10!white}
\newtcolorbox{importantBox}{textmarker,
    borderline west={6pt}{0pt}{red},
    colback=red!10!white}
\newtcolorbox{noteBox}{textmarker,
    borderline west={6pt}{0pt}{green},
    colback=green!10!white}

% define commands for easy access
\newcommand{\note}[1]{\begin{noteBox} \textbf{Note:} #1 \end{noteBox}}
\newcommand{\warning}[1]{\begin{hintBox} \textbf{Warning:} #1 \end{hintBox}}
\newcommand{\important}[1]{\begin{importantBox} \textbf{Important:} #1 \end{importantBox}}

\hypersetup{citecolor=blue}

\definecolor{MSBlue}{rgb}{.204,.353,.541}
\usepackage{titlesec}
\titleformat*{\section}{\color{MSBlue}}
\titleformat*{\subsection}{\color{MSBlue}}
\setlength{\parindent}{0pt}


% Title and author information
\title{Residual and ensemble regression for improved reconstruction of high-energy gamma-ray events}
\author{Gernot Maier}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
High-energy gamma-ray astronomy
relies on the detection of Cherenkov light emitted by
air showers generated by the interaction of high-energy photons with Earth's atmosphere.
Observatories like CTAO or VERITAS use multiple telescopes to record images of these air showers
to derive direction and energy of the primary photon.
Multiple reconstruction methods are used in the field; all providing different levels of performance
depending on observation condition and gamma-ray energy.
This paper presents a machine-learning (gradient-boosted regression trees) based approach
with two main objectives:
learn from the errors of existing reconstruction methods and learn how to combine the results from
multiple reconstruction methods.
The evaluation based on simulated events and observations of the Crab Nebula shows improvements in
energy and angular resolution significantly compared to the standard reconstruction methods.
\end{abstract}

\section{Introduction}

Very-high energy gamma-ray astronomy uses Imaging Atmospheric Cherenkov Telescopes (IACTs)
to detect and reconstruct gamma-ray induced air showers in the atmosphere
(e.g., \citep{2009ARA&A..47..523H}).
The telescopes record the Cherenkov light emitted by the air showers using
pixelated cameras combined with fast electronics and trigger systems.
Modern observatories measure the projections of the air showers with multiple telescopes
simultaneously, allowing stereoscopic methods applied to reconstruction primary direction
and energy.
The technique is limited by intrinsic fluctuations of the air showers and
the photon-detection efficiency of the telescopes to estimated
1 (0.3) arcmin angular resolution at 100 GeV (1 TeV)
\citep{hofmann2006performancelimitscherenkovinstruments}.

The fields knows a variety of reconstruction methods for direction and energy estimation,
including geometric methods based on image parameters \citep{1997APh.....8....1D, 1999APh....12..135H},
template-model based methods \citep{2001A&A...374..895P,2009APh....32..231D,2014APh....56...26P},
and machine-learning-based methods using
Hillas parameters \citep{2024A&A...691A.328A} or full camera images.
Performance vary between the methods, with variations in achieved precision,
robustness against changing observation conditions, and computational requirements
on e.g., Monte-Carlo simulations required to calculate templates or provide training events.



This is a template document for the Eventdisplay Machine Learning paper.
The Eventdisplay-ML project can be found at \citep{maier_2026_18412988}.

\begin{itemize}
  \item IACT event reconstruction
  \item Energy and direction regression
  \item Machine-learning-based reconstruction
    \item Limitations of classical geometric reconstruction (Hillas-based intersection).
    \item Objective: Improving angular and energy resolution via Multi-target Regression.
    \item Motivation for Gradient Boosting in high-dynamic-range scientific data.
  \item Standard Eventdisplay methods
  \item Integrated in existing pipeline (thin additional layer)
  \item awareness that a complete rewrite of the analysis would be clear, but not feasible
  \item importance of stability and robustness
  \item Statement of the Problem
\end{itemize}

\section{Data Pipeline and Feature Engineering}

\begin{itemize}
  \item Training with Monte Carlo air-shower simulations
  \item Array layout, telescope multiplicity
  \item Energy, zenith, offset distributions
  \item Eventdisplay-derived parameters
  \item sorting by mirror area (telescope type) and size
    \item \textbf{Ground Truth Labels:} Monte Carlo simulated primary energy ($MCe0$) and arrival direction offsets ($MCxoff, MCyoff$).
    \item \textbf{Stereo Input Features:} Multi-telescope image parameters (Size, Width, Length, Distance, $\chi^2$ emission height).
    \item \textbf{Geomagnetic Corrections:} Calculation of shower angles relative to the Earth's magnetic field ($\theta_B$) to account for Lorentz force broadening.
    \item \textbf{Data Transformation:} Logarithmic scaling of intensity (Size) and energy to handle power-law distributions.
    \item \textbf{Handling Multiplicity:} Flattening heterogeneous telescope array data into unified feature vectors for $N$-telescope events.
  \item clipping and transformations (log size, log energy)
  \item Train / validation / test samples
  \item Evaluation with Crab Nebula data
\end{itemize}

\section{Regression Targets and Performance Metrics}

\begin{itemize}
  \item Energy bias
  \item Energy resolution (68\% containment)
  \item Angular resolution (PSF containment)
\end{itemize}

\section{Model Architecture and Training}

\begin{itemize}
  \item regression targets: energy, direction (x,y)
  \item multi-target regression
  \item gradient-boosted decision trees (XGBoost)
  \item Gradient-boosted decision trees
  \item Loss functions
  \item Regularization and depth control
    \item \textbf{Hyperparameters:} Optimization of tree depth (max\_depth=10), learning rate (0.1), and subsampling (0.7).
    \item \textbf{Loss Function:} \texttt{reg:squarederror} optimized for residuals in spatial and energy domains.
    \item \textbf{Weighted Learning:} Implementation of inverse-count energy weighting and multiplicity weighting (proportional to $N_{images}^2$) to balance the training set.
\end{itemize}

\textbf{Suggested tables:}
\begin{itemize}
  \item Hyperparameter summary
\end{itemize}

\subsection{Training and Validation Strategy}

\begin{itemize}
    \item feature importance
    \item feature correlations
  \item Independent test sample
  \item Energy-binned evaluation
  \item Overfitting control
\end{itemize}

\textbf{Suggested plots/tables:}
\begin{itemize}
  \item Feature correlation matrix
  \item Feature importance ranking
  \item Training vs validation loss
\end{itemize}

\section{Performance Evaluation}

\textbf{Suggested plots/tables:}
\begin{itemize}
  \item \textbf{Interpretability:} Global feature importance ranking (SHAP/Gain) for energy vs. directionality.
  \item Energy resolution vs true energy
  \item Angular resolution vs energy
  \item Energy bias vs true energy
  \item cumulative distributions for MC and Crab data
  \item theta2 plots for Crab data
\end{itemize}

\section{Systematic Effects and Robustness}
\begin{itemize}
  \item Zenith-angle dependence
  \item Offset dependence
  \item Domain shift sensitivity
  \item missing telescopes (3-telescope reconstruction)
\end{itemize}
\textbf{Suggested plots:}
\begin{itemize}
  \item Performance vs zenith
  \item Performance vs offset
\end{itemize}

\section{Conclusions}
\begin{itemize}
  \item Impact
  \item Limitations
  \item Summary of regression performance
\end{itemize}


\section*{AI usage disclosure}

Generative AI tools (including Claude, ChatGPT, and Gemini) were used to assist
with code development and debugging of the code associated to this paper.
AI tools are also used for language improvement of this text.
All AI-assisted outputs were reviewed, validated, and, where necessary,
modified by the authors to ensure accuracy and reliability.

\section*{Acknowledgments}

Add acknowledgments here.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliographystyle{aasjournal}
\bibliography{bibliography}%

\end{document}
